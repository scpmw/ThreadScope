\section{Profiling Motivation}
Show examples of semi-explicit parallel programs that go wrong. Show what we could measure before using heap and time profiling and motivate the need for better profiling.

Haskell provides a mechanism to allow the user to control the granularity of parallelism by indicating what computations may be usefully carried out in parallel. This is done by using functions from the \codef{Control.Parallel} module. The interface for \codef{Control.Parallel} is shown below:
\begin{lstlisting}
  par :: a -> b -> b 
  pseq :: a -> b -> b 
\end{lstlisting}
The function \codef{par} indicates to the GHC run-time system that it may be beneficial to evaluate the first argument in parallel with the second argument. The \codef{par} function returns as its result the value of the second argument. One can always eliminate \codef{par} from a program by using the following identity without altering the semantics of the program:
\begin{lstlisting}
  par a b = b 
\end{lstlisting}
A thread is not necessarily created to compute the value of the expression \codef{a}. Instead, the GHC run-time system creates a {\em spark} which has the potential to be executed on a different thread from the parent thread. A sparked computation expresses the possibility of performing some speculative evaluation. Since a thread is not necessarily created to compute the value of \codef{a} this approach has some similarities with the notion of a {\em lazy future}~\cite{mohr:91}.

Sometimes it is convenient to write a function with two arguments as an infix function and this is done in Haskell by writing quotes around the function:
\begin{lstlisting}
  a `par` b
\end{lstlisting}

We call such programs semi-explicitly parallel because the programmer has provided a hint about the appropriate level of granularity for parallel operations and the system implicitly creates threads to implement the concurrency. The user does not need to explicitly create any threads or write any code for inter-thread communication or synchronization.

To illustrate the use of \codef{par} we present a program that performs two compute intensive functions in parallel. The first compute intensive function we use is the notorious Fibonacci function:
\begin{lstlisting}
fib :: Int -> Int
fib 0 = 0
fib 1 = 1
fib n = fib (n-1) + fib (n-2)
\end{lstlisting}
The second compute intensive function we use is the \codef{sumEuler} function taken from~\cite{trinder:02}:
\begin{lstlisting}
mkList :: Int -> [Int]
mkList n = [1..n-1]

relprime :: Int -> Int -> Bool
relprime x y = gcd x y == 1

euler :: Int -> Int
euler n = length (filter (relprime n) (mkList n))

sumEuler :: Int -> Int
sumEuler = sum . (map euler) . mkList
\end{lstlisting}
The function that we wish to parallelize adds the results of calling \codef{fib} and \codef{sumEuler}:
\begin{lstlisting}
sumFibEuler :: Int -> Int -> Int
sumFibEuler a b = fib a + sumEuler b
\end{lstlisting}
As a first attempt we can try to use \codef{par} the speculatively spark off the computation of \codef{fib} while the parent thread works on \codef{sumEuler}:
\begin{lstlisting}
-- A wrong way to parallelize f + e
parSumFibEuler :: Int -> Int -> Int
parSumFibEuler a b
  = f `par` (f + e)
    where
    f = fib a
    e = sumEuler b
\end{lstlisting}

To create two workloads that take roughly the same amount of time to execute we performed some experiments which show that \codef{fib 38} takes roughly the same time to execute as \codef{sumEuler 5300}. If we were to run this program and view the execution trace we would see somthing like the graph shown in Figure~\ref{f:wrongpar}.

\begin{figure}
\begin{center}
\includegraphics[width=8.5cm]{SumEuler1-N2-eventlog.pdf}
\end{center}
\caption{No parallelization of \codef{f `par` (f + e)}}
\label{f:wrongpar}
\end{figure}

We can examine an execution log to help understand what went wrong:

\begin{verbatim}
  SPARKS: 1 (0 converted, 0 pruned)

  INIT  time    0.00s  (  0.00s elapsed)
  MUT   time    9.39s  (  9.61s elapsed)
  GC    time    0.37s  (  0.24s elapsed)
  EXIT  time    0.00s  (  0.00s elapsed)
  Total time    9.77s  (  9.85s elapsed)
\end{verbatim}

The log shows that although a spark was created for the potential parallel evaluation of \codef{fib 38} it was never picked up for evaluation. In this case the performance bug is due to the fact that the main thread immediately starts to work on the evaluation of \codef{fib 38} itself which causes this spark to fizzle. One might be tempted to fix this problem by swapping the arguments to the \codef{+} operator in the hope that the main thread will work on \codef{sumEuler} while the sparked thread works on \codef{fib}:

\begin{lstlisting}
-- Maybe a lucky parallelization
parSumFibEuler :: Int -> Int -> Int
parSumFibEuler a b
  = f `par` (e + f)
    where
    f = fib a
    e = sumEuler b
\end{lstlisting}

This results in the execution trace shown in Figure~\ref{f:lucky} which shows a sparked thread being taken up by a spare worker thread. 

\begin{figure}
\begin{center}
\includegraphics[width=8.5cm]{SumEuler2-N2-eventlog.pdf}
\end{center}
\caption{A luck parallelization of \codef{f `par` (e + f)}}
\label{f:wrongpar}
\end{figure}

The execution log for this program shows that a spark was used productively and the elapsed time has dropped from 9.85s to 5.33s:

\begin{verbatim}
  SPARKS: 1 (1 converted, 0 pruned)

  INIT  time    0.00s  (  0.00s elapsed)
  MUT   time    9.47s  (  4.91s elapsed)
  GC    time    0.69s  (  0.42s elapsed)
  EXIT  time    0.00s  (  0.00s elapsed)
  Total time   10.16s  (  5.33s elapsed)
\end{verbatim}

The better way to evaluate \codef{fib} and \codef{sumEuler} in parallel is to used the \codef{pseq} combinator to ensure that the main thread works on \codef{suMEuler} while the sparked thread works on \codef{fib}:

\begin{lstlisting}
-- A correct parallelization that does not depend on
-- the evaluation order of +
parSumFibEuler :: Int -> Int -> Int
parSumFibEuler a b
  = f `par` (e `pseq` (f + e))
    where
    f = fib a
    e = sumEuler b
\end{lstlisting}

This version does not make any assumptions about the evaluation order of \codef{+} which is undefined in Haskell.

This example as well as our wider experience of attempting to write semi-explicit parallel programs shows that it is often very difficult to understand if and when opportunities for parallelism expressed through \codef{par} are effectively taken up and to also understand how operations like garbage collection influence the performance of the program. Until recently one only had available high level summary information about the overall execution of a parallel Haskell program. In this paper we describe recent improvements to the Haskell run-time which allow a much more detailed profile to be generated which can then be used to help debug performance problems.
